---
title: How to cluster my Giotto object?
output:
  html_document:
    toc: yes
    toc_depth: '2'
    df_print: paged
  github_document:
    toc: yes
    toc_depth: 2
---


This tutorial will take you through the dimension reduction and clustering capabilities of Giotto. The starting point is a Giotto object that has already gone through data processing- more details on that process can be found in the data processing tutorial.

This tutorial uses a SeqFISH+ dataset of a murine cortex and subventrical zone. A complete walkthough of that dataset can be found [**here**](./SeqFISH_cortex_210923.html).

# Creating and Processing a Giotto Object

```{r, eval=FALSE}
library(Giotto)
my_working_dir = '/path/to/directory/'

# set python path to your preferred python version path
# set python path to NULL if you want to automatically install (only the 1st time) and use the giotto miniconda environment
python_path = NULL 
if(is.null(python_path)) {
  installGiottoEnvironment(force_environment = TRUE)
}

getSpatialDataset(dataset = 'seqfish_SS_cortex', directory = my_working_dir, method = 'wget')

#  set Giotto instructions
instrs = createGiottoInstructions(save_plot = TRUE, 
                                  show_plot = FALSE,
                                  save_dir = my_working_dir, 
                                  python_path = NULL)

# create giotto object from provided paths ####
expr_path = paste0(my_working_dir, "cortex_svz_expression.txt")
loc_path = paste0(my_working_dir, "cortex_svz_centroids_coord.txt")
meta_path = paste0(my_working_dir, "cortex_svz_centroids_annot.txt")


#This dataset contains multiple field of views which need to be stitched together

# first merge location and additional metadata
SS_locations = data.table::fread(loc_path)
cortex_fields = data.table::fread(meta_path)
SS_loc_annot = data.table::merge.data.table(SS_locations, cortex_fields, by = 'ID')
SS_loc_annot[, ID := factor(ID, levels = paste0('cell_',1:913))]
data.table::setorder(SS_loc_annot, ID)

# create file with offset information
my_offset_file = data.table::data.table(field = c(0, 1, 2, 3, 4, 5, 6),
                                        x_offset = c(0, 1654.97, 1750.75, 1674.35, 675.5, 2048, 675),
                                        y_offset = c(0, 0, 0, 0, -1438.02, -1438.02, 0))

# create a stitch file
stitch_file = stitchFieldCoordinates(location_file = SS_loc_annot,
                                     offset_file = my_offset_file,
                                     cumulate_offset_x = T,
                                     cumulate_offset_y = F,
                                     field_col = 'FOV',
                                     reverse_final_x = F,
                                     reverse_final_y = T)
stitch_file    = stitch_file[,.(ID, X_final, Y_final)]
my_offset_file = my_offset_file[,.(field, x_offset_final, y_offset_final)]

# create Giotto object
testobj <- createGiottoObject(expression = expr_path,
                                 spatial_locs = stitch_file,
                                 offset_file = my_offset_file,
                                 instructions = instrs)

# add additional annotation if wanted
testobj = addCellMetadata(testobj,
                             new_metadata = cortex_fields,
                             by_column = T,
                             column_cell_ID = 'ID')

# subset data to the cortex field of views
cell_metadata = pDataDT(testobj)
cortex_cell_ids = cell_metadata[FOV %in% 0:4]$cell_ID
testobj = subsetGiotto(testobj, cell_ids = cortex_cell_ids)

# Process the Giotto object, filtering, normalization, adding statistics and correcting for covariates
processGiotto(testobj,filter_params = list(expression_threshold = 1,feat_det_in_min_cells = 100, min_det_feats_per_cell = 10),
                      norm_params = list( norm_methods = 'standard', scale_feats = TRUE, scalefactor = 6000),
                      stat_params = list(expression_values = 'normalized'),
                      adjust_params = list(expression_values = c('normalized')))



```


## 1. Dimension Reduction and PCA
You can compute highly variable genes based on high coefficient of variance within groups, loess regression predictions, or variance of pearson residuals for each gene, based on which **method** is selected. 
```{r, eval=FALSE}
#calculate HVF using the loess regression prediction model
testobj <- calculateHVF(gobject = testobj, method = 'cov_groups')

```
![](../inst/images/SeqFish_mouse_cortex/0-HVFplot.png){ width=50% } 
```{r, eval=FALSE}
#calculate HVF using the loess regression prediction model
testobj <- calculateHVF(gobject = testobj, method = 'cov_loess')

```
![](../inst/images/SeqFish_mouse_cortex/2-HVFplot.png){ width=50% } 
```{r, eval=FALSE}
#calculate HVF using the loess regression prediction model
testobj <- calculateHVF(gobject = testobj, method = 'var_p_resid')

```
![](../inst/images/SeqFish_mouse_cortex/1-HVFplot.png){ width=50% } 

You can then run a PCA based on the highly variable genes. After the PCA you can run a TSNE, a UMAP, or both.
```{r, eval=FALSE}
## select genes based on HVG and gene statistics, both found in gene metadata
gene_metadata = fDataDT(testobj)
featgenes = gene_metadata[hvf == 'yes' & perc_cells > 4 & mean_expr_det > 0.5]$gene_ID

## run PCA on expression values (default)
testobj <- runPCA(gobject = testobj, genes_to_use = featgenes, scale_unit = F, center = F)

# plot a scree plot
screePlot(SS_seqfish)
```
![](../inst/images/SeqFish_mouse_cortex/2-screePlot.png){ width=50% }

```{r, eval=FALSE}
# Plot a PCA
plotPCA(gobject = SS_seqfish)
```
![](../inst/images/SeqFish_mouse_cortex/3-PCA.png){ width=50% }

```{r, eval=FALSE}
# Run a TSNE based on PCA dimension reduction
testobj <- runtSNE(testobj, dimensions_to_use = 1:15)
plotTSNE(gobject = SS_seqfish)
```
![](../inst/images/SeqFish_mouse_cortex/5-tSNE.png){ width=50% }


```{r, eval=FALSE}
# Run a UMAP based on PCA dimension reduction
testobj <- runUMAP(testobj, dimensions_to_use = 1:15)
# view pre-clustering UMAP
plotUMAP(gobject = testobj)
```
![](../inst/images/SeqFish_mouse_cortex/4-UMAP.png){ width=50% }


## 2. Clustering
Clustering your cells into distinct groups based on feature expression. The input is a Giotto object that has undergone either TSNE or UMAP dimension reduction.
```{r, eval=FALSE}
## create a shared nearest neighbor network (sNN), where k is the number of k niehgbors to use
testobj <- createNearestNetwork(gobject = testobj, dimensions_to_use = 1:15, k = 15)
```

Cells can be clustered in Giotto using k-means, Leiden, or Louvain clustering
```{r, eval=FALSE}
## k-means clustering
testobj <- doKmeans(gobject = testobj, dim_reduction_to_use = 'pca')

## Leiden clustering- increase the resolution to increase the number of clusters
testobj <- doLeidenCluster(gobject = testobj, resolution = 0.4, n_iterations = 1000)

## Louvain clustering- increase the resolution to increase the number of clusters
testobj <- doLeidenCluster(gobject = testobj, version = 'community', resolution = 0.4)

#Plot UMAP post-clustering to visualize clusters
plotUMAP(gobject = testobj,
         cell_color = 'leiden_clus', show_NN_network = T, point_size = 2.5)
```
![](../inst/images/SeqFish_mouse_cortex/6-UMAP.png){ width=50% } 

Clusters of interest can be further sub-clustered, choose your clusters with **selected_clusters**
```{r, eval=FALSE}
## Leiden subclustering for specified clusters
testobj = doLeidenSubCluster(gobject = testobj, cluster_column = 'leiden_clus',
                                resolution = 0.2, k_neighbors = 10,
                                hvf_param = list(method = 'cov_loess', difference_in_cov = 0.1),
                                pca_param = list(expression_values = 'normalized', scale_unit = F),
                                nn_param = list(dimensions_to_use = 1:5),
                                selected_clusters = c(5, 6, 7),
                                name = 'sub_leiden_clus_select')

#Plot a UMAP to visualize your sub-clustering
plotUMAP(gobject = testobj, cell_color = 'sub_leiden_clus_select', show_NN_network = T)

```
![](../inst/images/SeqFish_mouse_cortex/10-UMAP.png){ width=50% } 
